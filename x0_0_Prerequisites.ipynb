{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is tested completely only on Python 3.10. Other 3.x versions may likely work, but not tested so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major, minor,*_ = sys.version_info\n",
    "assert (major,minor) == (3, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%pip install graphviz==0.19.2 fuzzingbook==1.0.7 sympy==1.10.1 z3-solver==4.8.16.0 ipynb==0.5.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**IMPORTANT:** Restart the jupyter kernal after installation of dependencies and extensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Jupyter Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We recommend the following jupyter notebook extensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%pip install jupyter_contrib_nbextensions jupyter_nbextensions_configurator==0.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!{sys.executable} -m jupyter contrib nbextension install --sys-prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!{sys.executable} -m jupyter nbextensions_configurator enable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Table of contents\n",
    "\n",
    "Please install this extension. The navigation in the notebook is rather hard without this installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!{sys.executable} -m jupyter nbextension enable toc2/main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Collapsible headings\n",
    "\n",
    "Again, do install this extension. This will let you fold away those sections that you do not have an immediate interest in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!{sys.executable} -m jupyter nbextension enable collapsible_headings/main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Code folding\n",
    "Very helpful for hiding away source contents of libraries that are not for grammar recovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!{sys.executable} -m jupyter nbextension enable codefolding/main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Cleanup\n",
    "Cleanup if we have already done this before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!rm -rf build src subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p build src subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils.py\n",
    "\n",
    "Utils.py contains a few helper routines that are used multiple times from other parts.\n",
    "\n",
    "### `do()`\n",
    "\n",
    "`do()` allows us to execute a system command and capture its output in a log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/utils.py\n",
    "import sys\n",
    "import subprocess\n",
    "from subprocess import run\n",
    "import os\n",
    "import json\n",
    "CMD_TIMEOUT=60*60*24\n",
    "\n",
    "class O:\n",
    "    def __init__(self, **keys): self.__dict__.update(keys)\n",
    "    def __repr__(self): return str(self.__dict__)\n",
    "\n",
    "def do(command, env=None, shell=False, log=False, inputv=None, timeout=CMD_TIMEOUT, **args):\n",
    "    result = None\n",
    "    if inputv:\n",
    "        result = subprocess.Popen(command,\n",
    "            stdin = subprocess.PIPE,\n",
    "            stdout = subprocess.PIPE,\n",
    "            stderr = subprocess.STDOUT,\n",
    "            shell = shell,\n",
    "            env=dict(os.environ, **({} if env is None else env))\n",
    "        )\n",
    "        result.stdin.write(inputv)\n",
    "        stdout, stderr = result.communicate(timeout=timeout)\n",
    "    else:\n",
    "        result = subprocess.Popen(command,\n",
    "            stdout = subprocess.PIPE,\n",
    "            stderr = subprocess.STDOUT,\n",
    "            shell = shell,\n",
    "            env=dict(os.environ, **({} if env is None else env))\n",
    "        )\n",
    "        stdout, stderr = result.communicate(timeout=timeout)\n",
    "    if log:\n",
    "         with open('build/do.log', 'a+') as f:\n",
    "            print(json.dumps({'cmd':command,\n",
    "                              'env':env,\n",
    "                              'exitcode':result.returncode}), env,\n",
    "                  flush=True, file=f)\n",
    "    stdout = '' if stdout is None else stdout.decode()\n",
    "    stderr = '' if stderr is None else stderr.decode()\n",
    "    result.kill()\n",
    "    return O(returncode=result.returncode, stdout=stdout, stderr=stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a src/utils.py\n",
    "import types\n",
    "\n",
    "def slurp(fn):\n",
    "    with open(fn) as f: return f.read()\n",
    "\n",
    "def load_src(src, mn):\n",
    "    module = types.ModuleType(mn)\n",
    "    exec(src, module.__dict__)\n",
    "    return module\n",
    "\n",
    "def load_file(fn, mn):\n",
    "    return load_src(slurp(fn), mn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExpectError\n",
    "\n",
    "`ExpectError` is a context manager that allows one to log an exception and continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a src/utils.py\n",
    "class ExpectError:\n",
    "    def __init__(self, log=True):\n",
    "        self.msg = None\n",
    "        self.log = log\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, tb):\n",
    "        if exc_type is None: return\n",
    "        self.msg = str(exc_value)\n",
    "        if self.log:\n",
    "            print(self.msg, file=sys.stderr)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python deepcopy is recursive; so it can't do the kind of recursive datastructures we use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a src/utils.py\n",
    "def to_tlv(ds):\n",
    "    expanded = []\n",
    "    to_expand = [ds]\n",
    "    while to_expand:\n",
    "        ds, *to_expand = to_expand\n",
    "        if type(ds) in {list, set, tuple}:\n",
    "            expanded.append(type(ds))\n",
    "            expanded.append(len(ds))\n",
    "            to_expand = list(ds) + to_expand\n",
    "        elif type(ds) in {dict}:\n",
    "            expanded.append(type(ds))\n",
    "            expanded.append(len(ds))\n",
    "            to_expand = list(ds.items()) + to_expand\n",
    "        else:\n",
    "            expanded.append(ds)\n",
    "    return list(reversed(expanded))\n",
    "\n",
    "def from_tlv(stk):\n",
    "    def get_children(result_stk):\n",
    "        l = result_stk.pop()\n",
    "        return [result_stk.pop() for i in range(l)]\n",
    "    i = 0\n",
    "    result_stk = []\n",
    "    while stk:\n",
    "        item, *stk = stk\n",
    "        if item == list:\n",
    "            ds = get_children(result_stk)\n",
    "            result_stk.append(ds)\n",
    "        elif item == set:\n",
    "            ds = get_children(result_stk)\n",
    "            result_stk.append(set(ds))\n",
    "        elif item == tuple:\n",
    "            ds = get_children(result_stk)\n",
    "            result_stk.append(tuple(ds))\n",
    "        elif item == dict:\n",
    "            ds = get_children(result_stk)\n",
    "            result_stk.append({i[0]:i[1]for i in ds})\n",
    "        else:\n",
    "            result_stk.append(item)\n",
    "    return result_stk[0]\n",
    "\n",
    "\n",
    "def deep_copy(arr):\n",
    "    val = to_tlv(arr)\n",
    "    return from_tlv(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DisplayTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a src/utils.py\n",
    "OPTIONS = O(V='|', H='-', L='+', J = '+')\n",
    "\n",
    "class Renderer:\n",
    "    def render(self): return None\n",
    "\n",
    "class DisplayTreeConsole:\n",
    "    def __init__(self, derivation_tree, verbose=False):\n",
    "        self.tree = derivation_tree\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def format_node(self, node):\n",
    "        key = node[0]\n",
    "        if key and (key[0], key[-1]) ==  ('<', '>'): return key\n",
    "        return repr(key)\n",
    "\n",
    "    def get_children(self, node):\n",
    "        return node[1]\n",
    "\n",
    "    def format_tree(self, node, options, prefix=''):\n",
    "        children = self.get_children(node)\n",
    "        if not children: return\n",
    "        *children, last_child = children\n",
    "        for child in children:\n",
    "            next_prefix = prefix + options.V + '   '\n",
    "            yield from self.format_child(child, next_prefix, options, prefix, False)\n",
    "        last_prefix = prefix + '    '\n",
    "        yield from self.format_child(last_child, last_prefix, options, prefix, True)\n",
    "\n",
    "    def format_child(self, child, next_prefix, options, prefix, last):\n",
    "        sep = (options.L if last else options.J)\n",
    "        yield prefix + sep + options.H + ' ' + self.format_node(child)\n",
    "        yield from self.format_tree(child, options, next_prefix)\n",
    "        \n",
    "    def display(self, options=OPTIONS):\n",
    "        print(self.format_node(self.tree))\n",
    "        for line in self.format_tree(self.tree, options):\n",
    "            print(line)\n",
    "        return Renderer() # noop\n",
    "\n",
    "def display_tree_console(tree, verbose=0):\n",
    "    DisplayTreeConsole(tree, verbose).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a src/utils.py\n",
    "if True: # switch this if you do not have graphviz installed.\n",
    "    from graphviz import Digraph    \n",
    "    from IPython.display import display                                                                            \n",
    "    import re\n",
    "\n",
    "    class DisplayTree:\n",
    "        def __init__(self, derivation_tree, verbose=False):\n",
    "            self.derivation_tree = derivation_tree\n",
    "            self.counter = 0\n",
    "            self.verbose = verbose\n",
    "\n",
    "        def unicode_escape(self, s, error = 'backslashreplace'):              \n",
    "            def ascii_chr(byte):                                             \n",
    "                if 0 <= byte <= 127:                                                     \n",
    "                    return chr(byte)                                                     \n",
    "                return r\"\\x%02x\" % byte                                                  \n",
    "\n",
    "            bytes = s.encode('utf-8', error)                                             \n",
    "            return \"\".join(map(ascii_chr, bytes))\n",
    "\n",
    "        def dot_escape(self, s):                                                   \n",
    "            \"\"\"Return s in a form suitable for dot\"\"\"                                    \n",
    "            s = re.sub(r'([^a-zA-Z0-9\" ])', r\"\\\\\\1\", s)                                  \n",
    "            return s                                                                     \n",
    "\n",
    "        def extract_node(self, node, id):                                                      \n",
    "            symbol, children, *annotation = node                                         \n",
    "            return symbol, children, ''.join(str(a) for a in annotation)                 \n",
    "\n",
    "        def node_attr(self, dot, nid, symbol, ann):                                    \n",
    "            dot.node(repr(nid), self.dot_escape(self.unicode_escape(symbol)))                      \n",
    "\n",
    "        def edge_attr(self, dot, start_node, stop_node):                               \n",
    "            dot.edge(repr(start_node), repr(stop_node))                                  \n",
    "\n",
    "        def graph_attr(self, dot):                                                     \n",
    "            dot.attr('node', shape='plain')                                              \n",
    "\n",
    "        def traverse_tree(self, dot, tree, id=0):                                          \n",
    "            (symbol, children, annotation) = self.extract_node(tree, id)                  \n",
    "            self.node_attr(dot, id, symbol, annotation)                                   \n",
    "\n",
    "            if children:                                                             \n",
    "                for child in children:                                               \n",
    "                    self.counter += 1                                                     \n",
    "                    child_id = self.counter                                               \n",
    "                    self.edge_attr(dot, id, child_id)                                     \n",
    "                    self.traverse_tree(dot, child, child_id)\n",
    "\n",
    "        def display(self):                                                            \n",
    "            dot = Digraph(comment=\"Derivation Tree\")                                     \n",
    "            self.graph_attr(dot)                                                              \n",
    "            self.traverse_tree(dot, self.derivation_tree)                                          \n",
    "            if self.verbose:                                                                \n",
    "                print(dot)                                                               \n",
    "            return dot\n",
    "\n",
    "    def display_tree(tree, verbose=0):\n",
    "        return DisplayTree(tree, verbose).display()\n",
    "else:\n",
    "    def display_tree(tree, verbose=0):\n",
    "        return DisplayTreeConsole(tree, verbose).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DisplayGrammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a src/utils.py\n",
    "def sort_grammar(grammar, start_symbol):\n",
    "    order = [start_symbol]\n",
    "    undefined = recurse_grammar(grammar, start_symbol, order)\n",
    "    return order, [k for k in grammar if k not in order], undefined\n",
    "\n",
    "def recurse_grammar(grammar, key, order, undefined=None):\n",
    "    undefined = undefined or {}\n",
    "    rules = sorted(grammar[key])\n",
    "    old_len = len(order)\n",
    "    for rule in rules:\n",
    "        for token in rule:\n",
    "            if not is_nt(token): continue\n",
    "            if token not in grammar:\n",
    "                if token in undefined:\n",
    "                    undefined[token].append(key)\n",
    "                else:\n",
    "                    undefined[token] = [key]\n",
    "                continue\n",
    "            if token not in order:\n",
    "                order.append(token)\n",
    "    new = order[old_len:]\n",
    "    for ckey in new:\n",
    "        recurse_grammar(grammar, ckey, order, undefined)\n",
    "    return undefined\n",
    "\n",
    "class DisplayGrammar:\n",
    "    def __init__(self, grammar, verbose=0):\n",
    "        self.grammar = grammar\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def is_nonterminal(self, key):\n",
    "        return is_nt(key)\n",
    "\n",
    "    def display_token(self, t):\n",
    "        return t if self.is_nonterminal(t) else repr(t)\n",
    "\n",
    "    def display_rule(self, rule, pre):\n",
    "        if self.verbose > -2:\n",
    "            v = (' '.join([self.display_token(t) for t in rule]))\n",
    "            s = '%s|   %s' % (pre, v)\n",
    "            print(s)\n",
    "\n",
    "    def display_definition(self, key, rule_count):\n",
    "        if self.verbose > -2: print(key,'::=')\n",
    "        for rule in self.grammar[key]:\n",
    "            rule_count += 1\n",
    "            if self.verbose > 1:\n",
    "                pre = rule_count\n",
    "            else:\n",
    "                pre = ''\n",
    "            self.display_rule(rule, pre)\n",
    "        return rule_count\n",
    "\n",
    "    def display_unused(self, not_used, r):\n",
    "        if not_used and self.verbose > -1:\n",
    "            print('[not_used]')\n",
    "            for key in not_used:\n",
    "                r = self.display_definition(key, r)\n",
    "                if self.verbose > 0:\n",
    "                    print(k, r)\n",
    "\n",
    "    def display_undefined(self, undefined):\n",
    "        if undefined and self.verbose > -1:\n",
    "            print('[undefined keys]')\n",
    "            for key in undefined:\n",
    "                if self.verbose == 0:\n",
    "                    print(key)\n",
    "                else:\n",
    "                    print(key, 'defined in')\n",
    "                    for k in undefined[key]: print(' ', k)\n",
    "\n",
    "    def display_summary(self, k, r):\n",
    "        if self.verbose > -1:\n",
    "            print('keys:', k, 'rules:', r)\n",
    "\n",
    "    def display(self, start):\n",
    "        rule_count, key_count = 0, 0\n",
    "        order, not_used, undefined = sort_grammar(self.grammar, start)\n",
    "        print('[start]:', start)\n",
    "        for key in order:\n",
    "            key_count += 1\n",
    "            rule_count = self.display_definition(key, rule_count)\n",
    "            if self.verbose > 0:\n",
    "                print(key_count, rule_count)\n",
    "\n",
    "        self.display_unused(not_used, rule_count)\n",
    "        self.display_undefined(undefined)\n",
    "        self.display_summary(key_count, rule_count)\n",
    "\n",
    "def display_grammar(grammar, start, verbose=0):\n",
    "    DisplayGrammar(grammar, verbose).display(start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a src/utils.py\n",
    "def tree_to_str(tree):\n",
    "    expanded = []\n",
    "    to_expand = [tree]\n",
    "    while to_expand:\n",
    "        (key, children, *rest), *to_expand = to_expand\n",
    "        if is_nt(key):\n",
    "            to_expand = list(children) + list(to_expand)\n",
    "        else:\n",
    "            assert not children\n",
    "            expanded.append(key)\n",
    "    return ''.join(expanded)\n",
    "\n",
    "def is_nt(v):\n",
    "    return v and (v[0], v[-1]) == ('<', '>')\n",
    "\n",
    "# A token is a lexer token from ANTLR. It is all uppercase nonterminal\n",
    "# but defined as a regular expression. For example <DIGITS>\n",
    "def is_token(val):\n",
    "    assert val != '<>'\n",
    "    assert (val[0], val[-1]) == ('<', '>')\n",
    "    if val[1].isupper(): return True\n",
    "    #if val[1] == '_': return val[2].isupper() # token derived.\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grammar GC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a src/utils.py\n",
    "# Grammar Cleanup\n",
    "def copy_grammar(g):\n",
    "    return {k:[[t for t in r] for r in g[k]] for k in g}\n",
    "\n",
    "def find_empty_keys(g):\n",
    "    return [k for k in g if not g[k]]\n",
    "\n",
    "def remove_nonterminal(nt, g):\n",
    "    new_g = {}\n",
    "    for k_ in g:\n",
    "        if k_ == nt: continue\n",
    "        new_rules = []\n",
    "        for rule in g[k_]:\n",
    "            if any(t == nt for t in rule): continue\n",
    "            new_rules.append(rule)\n",
    "        new_g[k_] = new_rules\n",
    "    return new_g\n",
    "\n",
    "def remove_empty_nonterminals(g):\n",
    "    new_g = copy_grammar(g)\n",
    "    removed_keys = []\n",
    "    empty_keys = find_empty_keys(new_g)\n",
    "    while empty_keys:\n",
    "        for k in empty_keys:\n",
    "            removed_keys.append(k)\n",
    "            new_g = remove_nonterminal(k, new_g)\n",
    "        empty_keys = find_empty_keys(new_g)\n",
    "    return new_g, removed_keys\n",
    "\n",
    "def grammar_gc(grammar, start, remove_unreachable=False):\n",
    "    new_grammar, removed = remove_empty_nonterminals(grammar)\n",
    "    if remove_unreachable:\n",
    "        order, not_used, undefined = sort_grammar(grammar, start)\n",
    "        return {k:new_grammar[k] for k in order}, start\n",
    "    return new_grammar, start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject Programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile subjects/calculator.py\n",
    "import string\n",
    "class MyException(Exception):\n",
    "    def __init__(self, s, i):\n",
    "        self.s = s\n",
    "        self.i = i\n",
    "\n",
    "def is_digit(i):\n",
    "    return i in string.digits\n",
    "    \n",
    "def parse_num(s,i):\n",
    "    n = ''\n",
    "    while s[i:] and is_digit(s[i]):\n",
    "        n += s[i]\n",
    "        i = i +1\n",
    "    return i,n\n",
    "\n",
    "def parse_paren(s, i):\n",
    "    assert s[i] == '('\n",
    "    i, v = parse_expr(s, i+1)\n",
    "    if s[i:] == '':\n",
    "        raise Exception(s, i)\n",
    "    assert s[i] == ')'\n",
    "    return i+1, v\n",
    "\n",
    "def parse_expr(s, i = 0):\n",
    "    expr = []\n",
    "    is_op = True\n",
    "    while s[i:]:\n",
    "        c = s[i]\n",
    "        if c in string.digits:\n",
    "            if not is_op: raise Exception(s,i)\n",
    "            i,num = parse_num(s,i)\n",
    "            expr.append(num)\n",
    "            is_op = False\n",
    "        elif c in ['+', '-', '*', '/']:\n",
    "            if is_op: raise Exception(s,i)\n",
    "            expr.append(c)\n",
    "            is_op = True\n",
    "            i = i + 1\n",
    "        elif c == '(':\n",
    "            if not is_op: raise Exception(s,i)\n",
    "            i, cexpr = parse_paren(s, i)\n",
    "            expr.append(cexpr)\n",
    "            is_op = False\n",
    "        elif c == ')':\n",
    "            break\n",
    "        else:\n",
    "            raise Exception(s,i)\n",
    "    if is_op:\n",
    "        raise Exception(s,i)\n",
    "    return i, expr\n",
    "\n",
    "def main(arg):\n",
    "    i, s = parse_expr(arg)\n",
    "    if len(arg) != i:\n",
    "        raise Exception(arg, i)\n",
    "    return i, s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Microjson.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile subjects/myio.py\n",
    "r\"\"\"File-like objects that read from or write to a string buffer.\n",
    "\n",
    "This implements (nearly) all stdio methods.\n",
    "\n",
    "f = StringIO()      # ready for writing\n",
    "f = StringIO(buf)   # ready for reading\n",
    "f.close()           # explicitly release resources held\n",
    "flag = f.isatty()   # always false\n",
    "pos = f.tell()      # get current position\n",
    "f.seek(pos)         # set current position\n",
    "f.seek(pos, mode)   # mode 0: absolute; 1: relative; 2: relative to EOF\n",
    "buf = f.read()      # read until EOF\n",
    "buf = f.read(n)     # read up to n bytes\n",
    "buf = f.readline()  # read until end of line ('\\n') or EOF\n",
    "list = f.readlines()# list of f.readline() results until EOF\n",
    "f.truncate([size])  # truncate file at to at most size (default: current pos)\n",
    "f.write(buf)        # write at current position\n",
    "f.writelines(list)  # for line in list: f.write(line)\n",
    "f.getvalue()        # return whole file's contents as a string\n",
    "\n",
    "Notes:\n",
    "- Using a real file is often faster (but less convenient).\n",
    "- There's also a much faster implementation in C, called cStringIO, but\n",
    "  it's not subclassable.\n",
    "- fileno() is left unimplemented so that code which uses it triggers\n",
    "  an exception early.\n",
    "- Seeking far beyond EOF and then writing will insert real null\n",
    "  bytes that occupy space in the buffer.\n",
    "- There's a simple test set (see end of this file).\n",
    "\"\"\"\n",
    "try:\n",
    "    from errno import EINVAL\n",
    "except ImportError:\n",
    "    EINVAL = 22\n",
    "\n",
    "__all__ = [\"StringIO\"]\n",
    "\n",
    "def _complain_ifclosed(closed):\n",
    "    if closed:\n",
    "        raise ValueError(\"I/O operation on closed file\")\n",
    "\n",
    "class StringIO:\n",
    "    \"\"\"class StringIO([buffer])\n",
    "\n",
    "    When a StringIO object is created, it can be initialized to an existing\n",
    "    string by passing the string to the constructor. If no string is given,\n",
    "    the StringIO will start empty.\n",
    "\n",
    "    The StringIO object can accept either Unicode or 8-bit strings, but\n",
    "    mixing the two may take some care. If both are used, 8-bit strings that\n",
    "    cannot be interpreted as 7-bit ASCII (that use the 8th bit) will cause\n",
    "    a UnicodeError to be raised when getvalue() is called.\n",
    "    \"\"\"\n",
    "    def __init__(self, buf = ''):\n",
    "        # Force self.buf to be a string or unicode\n",
    "        if not isinstance(buf, str):\n",
    "            buf = str(buf)\n",
    "        self.buf = buf\n",
    "        self.len = len(buf)\n",
    "        self.buflist = []\n",
    "        self.pos = 0\n",
    "        self.closed = False\n",
    "        self.softspace = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        \"\"\"A file object is its own iterator, for example iter(f) returns f\n",
    "        (unless f is closed). When a file is used as an iterator, typically\n",
    "        in a for loop (for example, for line in f: print line), the next()\n",
    "        method is called repeatedly. This method returns the next input line,\n",
    "        or raises StopIteration when EOF is hit.\n",
    "        \"\"\"\n",
    "        _complain_ifclosed(self.closed)\n",
    "        r = self.readline()\n",
    "        if not r:\n",
    "            raise StopIteration\n",
    "        return r\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Free the memory buffer.\n",
    "        \"\"\"\n",
    "        if not self.closed:\n",
    "            self.closed = True\n",
    "            del self.buf, self.pos\n",
    "\n",
    "    def isatty(self):\n",
    "        \"\"\"Returns False because StringIO objects are not connected to a\n",
    "        tty-like device.\n",
    "        \"\"\"\n",
    "        _complain_ifclosed(self.closed)\n",
    "        return False\n",
    "\n",
    "    def seek(self, pos, mode = 0):\n",
    "        \"\"\"Set the file's current position.\n",
    "\n",
    "        The mode argument is optional and defaults to 0 (absolute file\n",
    "        positioning); other values are 1 (seek relative to the current\n",
    "        position) and 2 (seek relative to the file's end).\n",
    "\n",
    "        There is no return value.\n",
    "        \"\"\"\n",
    "        _complain_ifclosed(self.closed)\n",
    "        if self.buflist:\n",
    "            self.buf += ''.join(self.buflist)\n",
    "            self.buflist = []\n",
    "        if mode == 1:\n",
    "            pos += self.pos\n",
    "        elif mode == 2:\n",
    "            pos += self.len\n",
    "        self.pos = max(0, pos)\n",
    "\n",
    "    def tell(self):\n",
    "        \"\"\"Return the file's current position.\"\"\"\n",
    "        _complain_ifclosed(self.closed)\n",
    "        return self.pos\n",
    "\n",
    "    def read(self, n = -1):\n",
    "        \"\"\"Read at most size bytes from the file\n",
    "        (less if the read hits EOF before obtaining size bytes).\n",
    "\n",
    "        If the size argument is negative or omitted, read all data until EOF\n",
    "        is reached. The bytes are returned as a string object. An empty\n",
    "        string is returned when EOF is encountered immediately.\n",
    "        \"\"\"\n",
    "        _complain_ifclosed(self.closed)\n",
    "        if self.buflist:\n",
    "            self.buf += ''.join(self.buflist)\n",
    "            self.buflist = []\n",
    "        if n is None or n < 0:\n",
    "            newpos = self.len\n",
    "        else:\n",
    "            newpos = min(self.pos+n, self.len)\n",
    "        r = self.buf[self.pos:newpos]\n",
    "        self.pos = newpos\n",
    "        return r\n",
    "\n",
    "    def readline(self, length=None):\n",
    "        r\"\"\"Read one entire line from the file.\n",
    "\n",
    "        A trailing newline character is kept in the string (but may be absent\n",
    "        when a file ends with an incomplete line). If the size argument is\n",
    "        present and non-negative, it is a maximum byte count (including the\n",
    "        trailing newline) and an incomplete line may be returned.\n",
    "\n",
    "        An empty string is returned only when EOF is encountered immediately.\n",
    "\n",
    "        Note: Unlike stdio's fgets(), the returned string contains null\n",
    "        characters ('\\0') if they occurred in the input.\n",
    "        \"\"\"\n",
    "        _complain_ifclosed(self.closed)\n",
    "        if self.buflist:\n",
    "            self.buf += ''.join(self.buflist)\n",
    "            self.buflist = []\n",
    "        i = self.buf.find('\\n', self.pos)\n",
    "        if i < 0:\n",
    "            newpos = self.len\n",
    "        else:\n",
    "            newpos = i+1\n",
    "        if length is not None and length > 0:\n",
    "            if self.pos + length < newpos:\n",
    "                newpos = self.pos + length\n",
    "        r = self.buf[self.pos:newpos]\n",
    "        self.pos = newpos\n",
    "        return r\n",
    "\n",
    "    def readlines(self, sizehint = 0):\n",
    "        \"\"\"Read until EOF using readline() and return a list containing the\n",
    "        lines thus read.\n",
    "\n",
    "        If the optional sizehint argument is present, instead of reading up\n",
    "        to EOF, whole lines totalling approximately sizehint bytes (or more\n",
    "        to accommodate a final whole line).\n",
    "        \"\"\"\n",
    "        total = 0\n",
    "        lines = []\n",
    "        line = self.readline()\n",
    "        while line:\n",
    "            lines.append(line)\n",
    "            total += len(line)\n",
    "            if 0 < sizehint <= total:\n",
    "                break\n",
    "            line = self.readline()\n",
    "        return lines\n",
    "\n",
    "    def truncate(self, size=None):\n",
    "        \"\"\"Truncate the file's size.\n",
    "\n",
    "        If the optional size argument is present, the file is truncated to\n",
    "        (at most) that size. The size defaults to the current position.\n",
    "        The current file position is not changed unless the position\n",
    "        is beyond the new file size.\n",
    "\n",
    "        If the specified size exceeds the file's current size, the\n",
    "        file remains unchanged.\n",
    "        \"\"\"\n",
    "        _complain_ifclosed(self.closed)\n",
    "        if size is None:\n",
    "            size = self.pos\n",
    "        elif size < 0:\n",
    "            raise IOError(EINVAL, \"Negative size not allowed\")\n",
    "        elif size < self.pos:\n",
    "            self.pos = size\n",
    "        self.buf = self.getvalue()[:size]\n",
    "        self.len = size\n",
    "\n",
    "    def write(self, s):\n",
    "        \"\"\"Write a string to the file.\n",
    "\n",
    "        There is no return value.\n",
    "        \"\"\"\n",
    "        _complain_ifclosed(self.closed)\n",
    "        if not s: return\n",
    "        # Force s to be a string or unicode\n",
    "        if not isinstance(s, str):\n",
    "            s = str(s)\n",
    "        spos = self.pos\n",
    "        slen = self.len\n",
    "        if spos == slen:\n",
    "            self.buflist.append(s)\n",
    "            self.len = self.pos = spos + len(s)\n",
    "            return\n",
    "        if spos > slen:\n",
    "            self.buflist.append('\\0'*(spos - slen))\n",
    "            slen = spos\n",
    "        newpos = spos + len(s)\n",
    "        if spos < slen:\n",
    "            if self.buflist:\n",
    "                self.buf += ''.join(self.buflist)\n",
    "            self.buflist = [self.buf[:spos], s, self.buf[newpos:]]\n",
    "            self.buf = ''\n",
    "            if newpos > slen:\n",
    "                slen = newpos\n",
    "        else:\n",
    "            self.buflist.append(s)\n",
    "            slen = newpos\n",
    "        self.len = slen\n",
    "        self.pos = newpos\n",
    "\n",
    "    def writelines(self, iterable):\n",
    "        \"\"\"Write a sequence of strings to the file. The sequence can be any\n",
    "        iterable object producing strings, typically a list of strings. There\n",
    "        is no return value.\n",
    "\n",
    "        (The name is intended to match readlines(); writelines() does not add\n",
    "        line separators.)\n",
    "        \"\"\"\n",
    "        write = self.write\n",
    "        for line in iterable:\n",
    "            write(line)\n",
    "\n",
    "    def flush(self):\n",
    "        \"\"\"Flush the internal buffer\n",
    "        \"\"\"\n",
    "        _complain_ifclosed(self.closed)\n",
    "\n",
    "    def getvalue(self):\n",
    "        \"\"\"\n",
    "        Retrieve the entire contents of the \"file\" at any time before\n",
    "        the StringIO object's close() method is called.\n",
    "\n",
    "        The StringIO object can accept either Unicode or 8-bit strings,\n",
    "        but mixing the two may take some care. If both are used, 8-bit\n",
    "        strings that cannot be interpreted as 7-bit ASCII (that use the\n",
    "        8th bit) will cause a UnicodeError to be raised when getvalue()\n",
    "        is called.\n",
    "        \"\"\"\n",
    "        if self.buflist:\n",
    "            self.buf += ''.join(self.buflist)\n",
    "            self.buflist = []\n",
    "        return self.buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile subjects/microjson.py\n",
    "# microjson - Minimal JSON parser/emitter for use in standalone scripts.\n",
    "# No warranty. Free to use/modify as you see fit. Trades speed for compactness.\n",
    "# Send ideas, bugs, simplifications to http://github.com/phensley\n",
    "# Copyright (c) 2010 Patrick Hensley <spaceboy@indirect.com>\n",
    "\n",
    "# std\n",
    "import math\n",
    "import subjects.myio as io\n",
    "import types\n",
    "\n",
    "\n",
    "# the '_from_json_number' function returns either float or long.\n",
    "__pychecker__ = 'no-returnvalues'\n",
    "\n",
    "# character classes\n",
    "WS = ' ' # ''.join([' ','\\t','\\r','\\n','\\b','\\f'])\n",
    "DIGITS = ''.join([str(i) for i in range(0, 10)])\n",
    "NUMSTART = DIGITS + ''.join(['.','-','+'])\n",
    "NUMCHARS = NUMSTART + ''.join(['e','E'])\n",
    "ESC_MAP = {'n':'\\n','t':'\\t','r':'\\r','b':'\\b','f':'\\f'}\n",
    "REV_ESC_MAP = dict([(_v,_k) for _k,_v in list(ESC_MAP.items())] + [('\"','\"')])\n",
    "\n",
    "# error messages\n",
    "E_BYTES = 'input string must be type str containing ASCII or UTF-8 bytes'\n",
    "E_MALF = 'malformed JSON data'\n",
    "E_TRUNC = 'truncated JSON data'\n",
    "E_BOOL = 'expected boolean'\n",
    "E_NULL = 'expected null'\n",
    "E_LITEM = 'expected list item'\n",
    "E_DKEY = 'expected key'\n",
    "E_COMMA = 'missing comma between elements'\n",
    "E_COLON = 'missing colon after key'\n",
    "E_EMPTY = 'found empty string, not valid JSON data'\n",
    "E_BADESC = 'bad escape character found'\n",
    "E_UNSUPP = 'unsupported type \"%s\" cannot be JSON-encoded'\n",
    "E_BADFLOAT = 'cannot emit floating point value \"%s\"'\n",
    "E_EXTRA = 'extra data after JSON'\n",
    "\n",
    "NEG_INF = float('-inf')\n",
    "POS_INF = float('inf')\n",
    "\n",
    "\n",
    "class JSONError(Exception):\n",
    "    def __init__(self, msg, stm=None, pos=0):\n",
    "        if stm:\n",
    "            msg += ' at position %d, \"%s\"' % (pos, repr(stm.substr(pos, 32)))\n",
    "        Exception.__init__(self, msg)\n",
    "        self.pos = pos\n",
    "\n",
    "\n",
    "class JSONStream:\n",
    "\n",
    "    # no longer inherit directly from StringIO, since we only want to\n",
    "    # expose the methods below and not allow direct access to the\n",
    "    # underlying stream.\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self._stm = io.StringIO(data)\n",
    "\n",
    "    @property\n",
    "    def pos(self):\n",
    "        return self._stm.tell()\n",
    "\n",
    "    @property\n",
    "    def len(self):\n",
    "        return len(self._stm.getvalue())\n",
    "\n",
    "    def getvalue(self):\n",
    "        return self._stm.getvalue()\n",
    "\n",
    "    def skipspaces(self):\n",
    "        \"post-cond: read pointer will be over first non-WS char\"\n",
    "        self._skip(lambda c: not c in WS)\n",
    "\n",
    "    def _skip(self, stopcond):\n",
    "        while True:\n",
    "            c = self.peek()\n",
    "            if stopcond(c) or c == '':\n",
    "                break\n",
    "            self.next()\n",
    "\n",
    "    def next(self, size=1):\n",
    "        return self._stm.read(size)\n",
    "\n",
    "    def next_ord(self):\n",
    "        return ord(next(self))\n",
    "\n",
    "    def peek(self):\n",
    "        if self.pos == self.len:\n",
    "            return self.getvalue()[self.pos:]\n",
    "        return self.getvalue()[self.pos]\n",
    "\n",
    "    def substr(self, pos, length):\n",
    "        return self.getvalue()[pos:pos+length]\n",
    "\n",
    "\n",
    "def _decode_utf8(c0, stm):\n",
    "    c0 = ord(c0)\n",
    "    r = 0xFFFD      # unicode replacement character\n",
    "    nc = stm.next_ord\n",
    "\n",
    "    # 110yyyyy 10zzzzzz\n",
    "    if (c0 & 0xE0) == 0xC0:\n",
    "        r = ((c0 & 0x1F) << 6) + (nc() & 0x3F)\n",
    "\n",
    "    # 1110xxxx 10yyyyyy 10zzzzzz\n",
    "    elif (c0 & 0xF0) == 0xE0:\n",
    "        r = ((c0 & 0x0F) << 12) + ((nc() & 0x3F) << 6) + (nc() & 0x3F)\n",
    "\n",
    "    # 11110www 10xxxxxx 10yyyyyy 10zzzzzz\n",
    "    elif (c0 & 0xF8) == 0xF0:\n",
    "        r = ((c0 & 0x07) << 18) + ((nc() & 0x3F) << 12) + \\\n",
    "            ((nc() & 0x3F) << 6) + (nc() & 0x3F)\n",
    "    return chr(r)\n",
    "\n",
    "\n",
    "def decode_escape(c, stm):\n",
    "    # whitespace\n",
    "    v = ESC_MAP.get(c, None)\n",
    "    if v is not None:\n",
    "        return v\n",
    "\n",
    "    # plain character\n",
    "    elif c != 'u':\n",
    "        return c\n",
    "\n",
    "    # decode unicode escape \\u1234\n",
    "    sv = 12\n",
    "    r = 0\n",
    "    for _ in range(0, 4):\n",
    "        r |= int(stm.next(), 16) << sv\n",
    "        sv -= 4\n",
    "    return chr(r)\n",
    "\n",
    "\n",
    "def _from_json_string(stm):\n",
    "    try:\n",
    "        # skip over '\"'\n",
    "        stm.next()\n",
    "        r = ''\n",
    "        while True:\n",
    "            c = stm.next()\n",
    "            if c == '':\n",
    "                raise JSONError(E_TRUNC, stm, stm.pos - 1)\n",
    "            elif c == '\\\\':\n",
    "                c = stm.next()\n",
    "                r += decode_escape(c, stm)\n",
    "            elif c == '\"':\n",
    "                return r\n",
    "            elif c in [str(i) for i in range(127, 256)]:\n",
    "                r += _decode_utf8(c, stm)\n",
    "            else:\n",
    "                r += c\n",
    "    except ValueError as v:\n",
    "        raise JSONError(E_MALF, stm, stm.pos)\n",
    "        \n",
    "\n",
    "def _from_json_fixed(stm, expected, value, errmsg):\n",
    "    off = len(expected)\n",
    "    pos = stm.pos\n",
    "    res = stm.substr(pos, off)\n",
    "    if res == expected:\n",
    "        stm.next(off)\n",
    "        return res\n",
    "    raise JSONError(errmsg, stm, pos)\n",
    "\n",
    "\n",
    "def _from_json_number(stm):\n",
    "    # Per rfc 4627 section 2.4 '0' and '0.1' are valid, but '01' and\n",
    "    # '01.1' are not, presumably since this would be confused with an\n",
    "    # octal number.  This rule is not enforced.\n",
    "    is_float = 0\n",
    "    saw_exp = 0\n",
    "    pos = stm.pos\n",
    "    while True:\n",
    "        c = stm.peek()\n",
    "        if not c: break\n",
    "\n",
    "        if not c in NUMCHARS:\n",
    "            break\n",
    "        elif c == '-' and not saw_exp:\n",
    "            pass\n",
    "        elif c in '.eE':\n",
    "            is_float = 1\n",
    "            if c in 'eE':\n",
    "                saw_exp = 1\n",
    "\n",
    "        stm.next()\n",
    "\n",
    "    s = stm.substr(pos, stm.pos - pos)\n",
    "    if is_float:\n",
    "        return s\n",
    "    return s\n",
    "\n",
    "\n",
    "def _from_json_list(stm):\n",
    "    # skip over '['\n",
    "    stm.next()\n",
    "    result = []\n",
    "    pos = stm.pos\n",
    "    comma = False\n",
    "    while True:\n",
    "        stm.skipspaces()\n",
    "        c = stm.peek()\n",
    "        if c == '':\n",
    "            raise JSONError(E_TRUNC, stm, pos)\n",
    "\n",
    "        elif c == ']':\n",
    "            stm.next()\n",
    "            return result\n",
    "\n",
    "        elif c == ',':\n",
    "            if not result:\n",
    "                raise JSONError(E_TRUNC, stm, pos)\n",
    "            if comma:\n",
    "                raise JSONError(E_TRUNC, stm, pos)\n",
    "            comma = True\n",
    "            stm.next()\n",
    "            result.append(_from_json_raw(stm))\n",
    "            comma = False\n",
    "            continue\n",
    "\n",
    "        elif not result:\n",
    "            # first item\n",
    "            result.append(_from_json_raw(stm))\n",
    "            comma = False\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            raise JSONError(E_MALF, stm, stm.pos)\n",
    "\n",
    "\n",
    "def _from_json_dict(stm):\n",
    "    # skip over '{'\n",
    "    stm.next()\n",
    "    result = {}\n",
    "    expect_key = 1\n",
    "    pos = stm.pos\n",
    "    comma = False\n",
    "    while True:\n",
    "        stm.skipspaces()\n",
    "        c = stm.peek()\n",
    "        if c == '':\n",
    "            raise JSONError(E_TRUNC, stm, pos)\n",
    "\n",
    "        # end of dictionary, or next item\n",
    "        elif c == '}':\n",
    "            if expect_key == 2:\n",
    "                raise JSONError(E_TRUNC, stm, pos)\n",
    "            stm.next()\n",
    "            return result\n",
    "\n",
    "        elif c == ',':\n",
    "            if not result:\n",
    "                raise JSONError(E_TRUNC, stm, pos)\n",
    "            if comma:\n",
    "                raise JSONError(E_TRUNC, stm, pos)\n",
    "            comma = True\n",
    "            stm.next()\n",
    "            expect_key = 2\n",
    "            continue\n",
    "\n",
    "        # parse out a key/value pair\n",
    "        elif c == '\"':\n",
    "            if not expect_key:\n",
    "                raise JSONError(E_COMMA, stm, stm.pos)\n",
    "            key = _from_json_string(stm)\n",
    "            stm.skipspaces()\n",
    "            c = stm.next()\n",
    "            if c != ':':\n",
    "                raise JSONError(E_COLON, stm, stm.pos)\n",
    "\n",
    "            stm.skipspaces()\n",
    "            val = _from_json_raw(stm)\n",
    "            result[key] = val\n",
    "            expect_key = 0\n",
    "            comma = False\n",
    "            continue\n",
    "\n",
    "        # unexpected character in middle of dict\n",
    "        raise JSONError(E_MALF, stm, stm.pos)\n",
    "\n",
    "\n",
    "def _from_json_raw(stm):\n",
    "    while True:\n",
    "        stm.skipspaces()\n",
    "        c = stm.peek()\n",
    "        if c == '\"': \n",
    "            return _from_json_string(stm)\n",
    "        elif c == '{': \n",
    "            return _from_json_dict(stm)\n",
    "        elif c == '[': \n",
    "            return _from_json_list(stm)\n",
    "        elif c == 't':\n",
    "            return _from_json_fixed(stm, 'true', True, E_BOOL)\n",
    "        elif c == 'f':\n",
    "            return _from_json_fixed(stm, 'false', False, E_BOOL)\n",
    "        elif c == 'n': \n",
    "            return _from_json_fixed(stm, 'null', None, E_NULL)\n",
    "        elif c in NUMSTART:\n",
    "            return _from_json_number(stm)\n",
    "\n",
    "        raise JSONError(E_MALF, stm, stm.pos)\n",
    "\n",
    "\n",
    "def from_json(data):\n",
    "    \"\"\"\n",
    "    Converts 'data' which is UTF-8 (or the 7-bit pure ASCII subset) into\n",
    "    a Python representation.  You must pass bytes to this in a str type,\n",
    "    not unicode.\n",
    "    \"\"\"\n",
    "    if not isinstance(data, str):\n",
    "        raise JSONError(E_BYTES)\n",
    "    if not data:\n",
    "        return None\n",
    "    stm = JSONStream(data)\n",
    "    v = _from_json_raw(stm)\n",
    "    c = stm.peek()\n",
    "    if c:\n",
    "        raise JSONError(E_EXTRA, stm, stm.pos)\n",
    "    return v\n",
    "\n",
    "\n",
    "# JSON emitter\n",
    "\n",
    "def _to_json_list(stm, lst):\n",
    "    seen = 0\n",
    "    stm.write('[')\n",
    "    for elem in lst:\n",
    "        if seen:\n",
    "            stm.write(',')\n",
    "        seen = 1\n",
    "        _to_json_object(stm, elem)\n",
    "    stm.write(']')\n",
    "\n",
    "\n",
    "def _to_json_string(stm, buf):\n",
    "    stm.write('\"')\n",
    "    for c in buf:\n",
    "        nc = REV_ESC_MAP.get(c, None)\n",
    "        if nc:\n",
    "            stm.write('\\\\' + nc)\n",
    "        elif ord(c) <= 0x7F:\n",
    "            # force ascii\n",
    "            stm.write(str(c))\n",
    "        else:\n",
    "            stm.write('\\\\u%04x' % ord(c))\n",
    "    stm.write('\"')\n",
    "\n",
    "\n",
    "def _to_json_dict(stm, dct):\n",
    "    seen = 0\n",
    "    stm.write('{')\n",
    "    for key in list(dct.keys()):\n",
    "        if seen:\n",
    "            stm.write(',')\n",
    "        seen = 1\n",
    "        val = dct[key]\n",
    "        if not type(key) in (bytes, str):\n",
    "            key = str(key)\n",
    "        _to_json_string(stm, key)\n",
    "        stm.write(':')\n",
    "        _to_json_object(stm, val)\n",
    "    stm.write('}')\n",
    "\n",
    "\n",
    "def _to_json_object(stm, obj):\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        _to_json_list(stm, obj)\n",
    "    elif isinstance(obj, bool):\n",
    "        if obj:\n",
    "            stm.write('true')\n",
    "        else:\n",
    "            stm.write('false')\n",
    "    elif isinstance(obj, float):\n",
    "        # this raises an error for NaN, -inf and inf values\n",
    "        if not (NEG_INF < obj < POS_INF):\n",
    "            raise JSONError(E_BADFLOAT % obj)\n",
    "        stm.write(\"%s\" % obj)\n",
    "    elif isinstance(obj, int):\n",
    "        stm.write(\"%d\" % obj)\n",
    "    elif isinstance(obj, type(None)):\n",
    "        stm.write('null')\n",
    "    elif isinstance(obj, (bytes, str)):\n",
    "        _to_json_string(stm, obj)\n",
    "    elif hasattr(obj, 'keys') and hasattr(obj, '__getitem__'):\n",
    "        _to_json_dict(stm, obj)\n",
    "    # fall back to implicit string conversion.\n",
    "    elif hasattr(obj, '__unicode__'):\n",
    "        _to_json_string(stm, obj.__unicode__())\n",
    "    elif hasattr(obj, '__str__'):\n",
    "        _to_json_string(stm, obj.__str__())\n",
    "    else:\n",
    "        raise JSONError(E_UNSUPP % type(obj))\n",
    "\n",
    "\n",
    "def to_json(obj):\n",
    "    \"\"\"\n",
    "    Converts 'obj' to an ASCII JSON string representation.\n",
    "    \"\"\"\n",
    "    stm = io.StringIO('')\n",
    "    _to_json_object(stm, obj)\n",
    "    return stm.getvalue()\n",
    "\n",
    "\n",
    "decode = from_json\n",
    "encode = to_json\n",
    "\n",
    "def main(arg):\n",
    "    return from_json(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile subjects/mylex.py\n",
    "\"\"\"A lexical analyzer class for simple shell-like syntaxes.\"\"\"\n",
    "\n",
    "# Module and documentation by Eric S. Raymond, 21 Dec 1998\n",
    "# Input stacking and error message cleanup added by ESR, March 2000\n",
    "# push_source() and pop_source() made explicit by ESR, January 2001.\n",
    "# Posix compliance, split(), string arguments, and\n",
    "# iterator interface by Gustavo Niemeyer, April 2003.\n",
    "# changes to tokenize more like Posix shells by Vinay Sajip, July 2016.\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from collections import deque\n",
    "\n",
    "from myio import StringIO\n",
    "\n",
    "__all__ = [\"shlex\", \"split\", \"quote\"]\n",
    "\n",
    "class shlex:\n",
    "    \"A lexical analyzer class for simple shell-like syntaxes.\"\n",
    "    def __init__(self, instream=None, infile=None, posix=False,\n",
    "                 punctuation_chars=False):\n",
    "        if isinstance(instream, str):\n",
    "            instream = StringIO(instream)\n",
    "        if instream is not None:\n",
    "            self.instream = instream\n",
    "            self.infile = infile\n",
    "        else:\n",
    "            self.instream = sys.stdin\n",
    "            self.infile = None\n",
    "        self.posix = posix\n",
    "        if posix:\n",
    "            self.eof = None\n",
    "        else:\n",
    "            self.eof = ''\n",
    "        self.commenters = '#'\n",
    "        self.wordchars = ('abcdfeghijklmnopqrstuvwxyz'\n",
    "                          'ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789_')\n",
    "        if self.posix:\n",
    "            self.wordchars += (''\n",
    "                               '')\n",
    "        self.whitespace = ' \\t\\r\\n'\n",
    "        self.whitespace_split = False\n",
    "        self.quotes = '\\'\"'\n",
    "        self.escape = '\\\\'\n",
    "        self.escapedquotes = '\"'\n",
    "        self.state = ' '\n",
    "        self.pushback = deque()\n",
    "        self.lineno = 1\n",
    "        self.debug = 0\n",
    "        self.token = ''\n",
    "        self.filestack = deque()\n",
    "        self.source = None\n",
    "        if not punctuation_chars:\n",
    "            punctuation_chars = ''\n",
    "        elif punctuation_chars is True:\n",
    "            punctuation_chars = '();<>|&'\n",
    "        self.punctuation_chars = punctuation_chars\n",
    "        if punctuation_chars:\n",
    "            # _pushback_chars is a push back queue used by lookahead logic\n",
    "            self._pushback_chars = deque()\n",
    "            # these chars added because allowed in file names, args, wildcards\n",
    "            self.wordchars += '~-./*?='\n",
    "            #remove any punctuation chars from wordchars\n",
    "            t = self.wordchars.maketrans(dict.fromkeys(punctuation_chars))\n",
    "            self.wordchars = self.wordchars.translate(t)\n",
    "\n",
    "    def push_token(self, tok):\n",
    "        \"Push a token onto the stack popped by the get_token method\"\n",
    "        if self.debug >= 1:\n",
    "            print(\"shlex: pushing token \" + repr(tok))\n",
    "        self.pushback.appendleft(tok)\n",
    "\n",
    "    def push_source(self, newstream, newfile=None):\n",
    "        \"Push an input source onto the lexer's input source stack.\"\n",
    "        if isinstance(newstream, str):\n",
    "            newstream = StringIO(newstream)\n",
    "        self.filestack.appendleft((self.infile, self.instream, self.lineno))\n",
    "        self.infile = newfile\n",
    "        self.instream = newstream\n",
    "        self.lineno = 1\n",
    "        if self.debug:\n",
    "            if newfile is not None:\n",
    "                print('shlex: pushing to file %s' % (self.infile,))\n",
    "            else:\n",
    "                print('shlex: pushing to stream %s' % (self.instream,))\n",
    "\n",
    "    def pop_source(self):\n",
    "        \"Pop the input source stack.\"\n",
    "        self.instream.close()\n",
    "        (self.infile, self.instream, self.lineno) = self.filestack.popleft()\n",
    "        if self.debug:\n",
    "            print('shlex: popping to %s, line %d' \\\n",
    "                  % (self.instream, self.lineno))\n",
    "        self.state = ' '\n",
    "\n",
    "    def get_token(self):\n",
    "        \"Get a token from the input stream (or from stack if it's nonempty)\"\n",
    "        if self.pushback:\n",
    "            tok = self.pushback.popleft()\n",
    "            if self.debug >= 1:\n",
    "                print(\"shlex: popping token \" + repr(tok))\n",
    "            return tok\n",
    "        # No pushback.  Get a token.\n",
    "        raw = self.read_token()\n",
    "        # Handle inclusions\n",
    "        if self.source is not None:\n",
    "            while raw == self.source:\n",
    "                spec = self.sourcehook(self.read_token())\n",
    "                if spec:\n",
    "                    (newfile, newstream) = spec\n",
    "                    self.push_source(newstream, newfile)\n",
    "                raw = self.get_token()\n",
    "        # Maybe we got EOF instead?\n",
    "        while raw == self.eof:\n",
    "            if not self.filestack:\n",
    "                return self.eof\n",
    "            else:\n",
    "                self.pop_source()\n",
    "                raw = self.get_token()\n",
    "        # Neither inclusion nor EOF\n",
    "        if self.debug >= 1:\n",
    "            if raw != self.eof:\n",
    "                print(\"shlex: token=\" + repr(raw))\n",
    "            else:\n",
    "                print(\"shlex: token=EOF\")\n",
    "        return raw\n",
    "\n",
    "    def read_token(self):\n",
    "        quoted = False\n",
    "        escapedstate = ' '\n",
    "        while True:\n",
    "            if self.punctuation_chars and self._pushback_chars:\n",
    "                nextchar = self._pushback_chars.pop()\n",
    "            else:\n",
    "                nextchar = self.instream.read(1)\n",
    "            if nextchar == '\\n':\n",
    "                self.lineno += 1\n",
    "            if self.debug >= 3:\n",
    "                print(\"shlex: in state %r I see character: %r\" % (self.state,\n",
    "                                                                  nextchar))\n",
    "            if self.state is None:\n",
    "                self.token = ''        # past end of file\n",
    "                break\n",
    "            elif self.state == ' ':\n",
    "                if not nextchar:\n",
    "                    self.state = None  # end of file\n",
    "                    break\n",
    "                elif nextchar in self.whitespace:\n",
    "                    if self.debug >= 2:\n",
    "                        print(\"shlex: I see whitespace in whitespace state\")\n",
    "                    if self.token or (self.posix and quoted):\n",
    "                        break   # emit current token\n",
    "                    else:\n",
    "                        continue\n",
    "                elif nextchar in self.commenters:\n",
    "                    self.instream.readline()\n",
    "                    self.lineno += 1\n",
    "                elif self.posix and nextchar in self.escape:\n",
    "                    escapedstate = 'a'\n",
    "                    self.state = nextchar\n",
    "                elif nextchar in self.wordchars:\n",
    "                    self.token = nextchar\n",
    "                    self.state = 'a'\n",
    "                elif nextchar in self.punctuation_chars:\n",
    "                    self.token = nextchar\n",
    "                    self.state = 'c'\n",
    "                elif nextchar in self.quotes:\n",
    "                    if not self.posix:\n",
    "                        self.token = nextchar\n",
    "                    self.state = nextchar\n",
    "                elif self.whitespace_split:\n",
    "                    self.token = nextchar\n",
    "                    self.state = 'a'\n",
    "                else:\n",
    "                    self.token = nextchar\n",
    "                    if self.token or (self.posix and quoted):\n",
    "                        break   # emit current token\n",
    "                    else:\n",
    "                        continue\n",
    "            elif self.state in self.quotes:\n",
    "                quoted = True\n",
    "                if not nextchar:      # end of file\n",
    "                    if self.debug >= 2:\n",
    "                        print(\"shlex: I see EOF in quotes state\")\n",
    "                    # XXX what error should be raised here?\n",
    "                    raise ValueError(\"No closing quotation\")\n",
    "                if nextchar == self.state:\n",
    "                    if not self.posix:\n",
    "                        self.token += nextchar\n",
    "                        self.state = ' '\n",
    "                        break\n",
    "                    else:\n",
    "                        self.state = 'a'\n",
    "                elif (self.posix and nextchar in self.escape and self.state\n",
    "                      in self.escapedquotes):\n",
    "                    escapedstate = self.state\n",
    "                    self.state = nextchar\n",
    "                else:\n",
    "                    self.token += nextchar\n",
    "            elif self.state in self.escape:\n",
    "                if not nextchar:      # end of file\n",
    "                    if self.debug >= 2:\n",
    "                        print(\"shlex: I see EOF in escape state\")\n",
    "                    # XXX what error should be raised here?\n",
    "                    raise ValueError(\"No escaped character\")\n",
    "                # In posix shells, only the quote itself or the escape\n",
    "                # character may be escaped within quotes.\n",
    "                if (escapedstate in self.quotes and\n",
    "                        nextchar != self.state and nextchar != escapedstate):\n",
    "                    self.token += self.state\n",
    "                self.token += nextchar\n",
    "                self.state = escapedstate\n",
    "            elif self.state in ('a', 'c'):\n",
    "                if not nextchar:\n",
    "                    self.state = None   # end of file\n",
    "                    break\n",
    "                elif nextchar in self.whitespace:\n",
    "                    if self.debug >= 2:\n",
    "                        print(\"shlex: I see whitespace in word state\")\n",
    "                    self.state = ' '\n",
    "                    if self.token or (self.posix and quoted):\n",
    "                        break   # emit current token\n",
    "                    else:\n",
    "                        continue\n",
    "                elif nextchar in self.commenters:\n",
    "                    self.instream.readline()\n",
    "                    self.lineno += 1\n",
    "                    if self.posix:\n",
    "                        self.state = ' '\n",
    "                        if self.token or (self.posix and quoted):\n",
    "                            break   # emit current token\n",
    "                        else:\n",
    "                            continue\n",
    "                elif self.state == 'c':\n",
    "                    if nextchar in self.punctuation_chars:\n",
    "                        self.token += nextchar\n",
    "                    else:\n",
    "                        if nextchar not in self.whitespace:\n",
    "                            self._pushback_chars.append(nextchar)\n",
    "                        self.state = ' '\n",
    "                        break\n",
    "                elif self.posix and nextchar in self.quotes:\n",
    "                    self.state = nextchar\n",
    "                elif self.posix and nextchar in self.escape:\n",
    "                    escapedstate = 'a'\n",
    "                    self.state = nextchar\n",
    "                elif (nextchar in self.wordchars or nextchar in self.quotes\n",
    "                      or self.whitespace_split):\n",
    "                    self.token += nextchar\n",
    "                else:\n",
    "                    if self.punctuation_chars:\n",
    "                        self._pushback_chars.append(nextchar)\n",
    "                    else:\n",
    "                        self.pushback.appendleft(nextchar)\n",
    "                    if self.debug >= 2:\n",
    "                        print(\"shlex: I see punctuation in word state\")\n",
    "                    self.state = ' '\n",
    "                    if self.token or (self.posix and quoted):\n",
    "                        break   # emit current token\n",
    "                    else:\n",
    "                        continue\n",
    "        result = self.token\n",
    "        self.token = ''\n",
    "        if self.posix and not quoted and result == '':\n",
    "            result = None\n",
    "        if self.debug > 1:\n",
    "            if result:\n",
    "                print(\"shlex: raw token=\" + repr(result))\n",
    "            else:\n",
    "                print(\"shlex: raw token=EOF\")\n",
    "        return result\n",
    "\n",
    "    def sourcehook(self, newfile):\n",
    "        \"Hook called on a filename to be sourced.\"\n",
    "        if newfile[0] == '\"':\n",
    "            newfile = newfile[1:-1]\n",
    "        # This implements cpp-like semantics for relative-path inclusion.\n",
    "        if isinstance(self.infile, str) and not os.path.isabs(newfile):\n",
    "            newfile = os.path.join(os.path.dirname(self.infile), newfile)\n",
    "        return (newfile, open(newfile, \"r\"))\n",
    "\n",
    "    def error_leader(self, infile=None, lineno=None):\n",
    "        \"Emit a C-compiler-like, Emacs-friendly error-message leader.\"\n",
    "        if infile is None:\n",
    "            infile = self.infile\n",
    "        if lineno is None:\n",
    "            lineno = self.lineno\n",
    "        return \"\\\"%s\\\", line %d: \" % (infile, lineno)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        token = self.get_token()\n",
    "        if token == self.eof:\n",
    "            raise StopIteration\n",
    "        return token\n",
    "\n",
    "def split(s, comments=False, posix=True):\n",
    "    lex = shlex(s, posix=posix)\n",
    "    lex.whitespace_split = True\n",
    "    if not comments:\n",
    "        lex.commenters = ''\n",
    "    return list(lex)\n",
    "\n",
    "\n",
    "_find_unsafe = re.compile(r'[^\\w@%+=:,./-]', re.ASCII).search\n",
    "\n",
    "def quote(s):\n",
    "    \"\"\"Return a shell-escaped version of the string *s*.\"\"\"\n",
    "    if not s:\n",
    "        return \"''\"\n",
    "    if _find_unsafe(s) is None:\n",
    "        return s\n",
    "\n",
    "    # use single quotes, and put single quotes into double quotes\n",
    "    # the string $'b is then quoted as '$'\"'\"'b'\n",
    "    return \"'\" + s.replace(\"'\", \"'\\\"'\\\"'\") + \"'\"\n",
    "\n",
    "\n",
    "def _print_tokens(lexer):\n",
    "    while 1:\n",
    "        tt = lexer.get_token()\n",
    "        if not tt:\n",
    "            break\n",
    "        print(\"Token: \" + repr(tt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "260px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
